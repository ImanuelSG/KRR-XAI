{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification Interpretability\n",
    "2. SHAP (SHapley Additive exPlanations)\n",
    "3. Layer-wise Relevance Propagation (LRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch pandas matplotlib numpy scikit-learn scipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.special import comb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './best_roberta_model'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with open(f'{model_path}/label_mappings.json', 'r') as f:\n",
    "    label_mappings = json.load(f)\n",
    "\n",
    "label_list = label_mappings['label_list']\n",
    "label2id = label_mappings['label2id']\n",
    "id2label = {int(k): v for k, v in label_mappings['id2label'].items()}\n",
    "\n",
    "def predict_sentiment(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "    return probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = [\n",
    "    \"This movie is absolutely fantastic! I loved every moment of it.\",\n",
    "    \"Terrible experience, waste of time and money. Very disappointed.\",\n",
    "    \"The product is okay, nothing special but does the job.\",\n",
    "    \"I'm extremely happy with this purchase! Highly recommend!\",\n",
    "    \"This is the worst service I've ever encountered. Absolutely horrible.\",\n",
    "    \"Not bad, could be better but acceptable for the price.\",\n",
    "    \"Outstanding quality! Exceeded all my expectations.\",\n",
    "    \"Mediocre at best, wouldn't buy again.\",\n",
    "    \"I feel neutral about this, it's just average.\",\n",
    "    \"Brilliant work! Truly exceptional and inspiring.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIMEExplainer:\n",
    "    def __init__(self, predict_fn, num_samples=1000):\n",
    "        self.predict_fn = predict_fn\n",
    "        self.num_samples = num_samples\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        return text.split()\n",
    "    \n",
    "    def kernel_fn(self, distances):\n",
    "        return np.sqrt(np.exp(-(distances ** 2) / 25 ** 2))\n",
    "    \n",
    "    def explain(self, text, target_class=None):\n",
    "        words = self.tokenize(text)\n",
    "        n_words = len(words)\n",
    "        \n",
    "        perturbations = np.random.binomial(1, 0.5, (self.num_samples, n_words))\n",
    "        perturbed_texts = [' '.join([w for w, m in zip(words, mask) if m == 1]) or '' \n",
    "                          for mask in perturbations]\n",
    "        \n",
    "        predictions = self.predict_fn(perturbed_texts)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = np.argmax(self.predict_fn([text])[0])\n",
    "        \n",
    "        y = predictions[:, target_class]\n",
    "        distances = np.sum(1 - perturbations, axis=1)\n",
    "        weights = self.kernel_fn(distances)\n",
    "        \n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(perturbations, y, sample_weight=weights)\n",
    "        \n",
    "        importance = list(zip(words, ridge.coef_))\n",
    "        importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        return importance, target_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHAPExplainer:\n",
    "    def __init__(self, predict_fn, num_samples=500):\n",
    "        self.predict_fn = predict_fn\n",
    "        self.num_samples = num_samples\n",
    "    \n",
    "    def shapley_kernel(self, n, s):\n",
    "        if s == 0 or s == n:\n",
    "            return 1e10\n",
    "        return (n - 1) / (comb(n, s) * s * (n - s))\n",
    "    \n",
    "    def explain(self, text, target_class=None):\n",
    "        words = text.split()\n",
    "        n_words = len(words)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = np.argmax(self.predict_fn([text])[0])\n",
    "        \n",
    "        empty_pred = self.predict_fn([''])[0, target_class]\n",
    "        shap_values = np.zeros(n_words)\n",
    "        \n",
    "        for _ in range(self.num_samples):\n",
    "            z = np.random.binomial(1, 0.5, n_words)\n",
    "            for i in range(n_words):\n",
    "                z_with, z_without = z.copy(), z.copy()\n",
    "                z_with[i], z_without[i] = 1, 0\n",
    "                \n",
    "                text_with = ' '.join([w for w, m in zip(words, z_with) if m == 1])\n",
    "                text_without = ' '.join([w for w, m in zip(words, z_without) if m == 1])\n",
    "                \n",
    "                pred_with = self.predict_fn([text_with])[0, target_class] if text_with else empty_pred\n",
    "                pred_without = self.predict_fn([text_without])[0, target_class] if text_without else empty_pred\n",
    "                \n",
    "                contrib = pred_with - pred_without\n",
    "                weight = self.shapley_kernel(n_words, np.sum(z_without))\n",
    "                shap_values[i] += contrib * weight\n",
    "        \n",
    "        shap_values /= self.num_samples\n",
    "        importance = list(zip(words, shap_values))\n",
    "        importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        return importance, target_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-wise Relevance Propagation (LRP) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRPExplainer:\n",
    "    def __init__(self, model, tokenizer, device, epsilon=1e-10):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def clean_token(self, token):\n",
    "        token = token.replace('Ġ', '').replace('</w>', '')\n",
    "        token = token.strip('▁')\n",
    "        if token in ['<s>', '</s>', '<pad>', '', 'Ċ']:\n",
    "            return None\n",
    "        return token\n",
    "    \n",
    "    def explain(self, text, target_class=None):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=64)\n",
    "        input_ids = inputs['input_ids'].to(self.device)\n",
    "        attention_mask = inputs['attention_mask'].to(self.device)\n",
    "        \n",
    "        embedding_layer = self.model.get_input_embeddings()\n",
    "        embeddings = embedding_layer(input_ids)\n",
    "        embeddings = embeddings.detach()\n",
    "        embeddings.requires_grad_(True)\n",
    "        \n",
    "        outputs = self.model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = outputs.logits.argmax().item()\n",
    "        \n",
    "        prediction_score = outputs.logits[0, target_class]\n",
    "        self.model.zero_grad()\n",
    "        if embeddings.grad is not None:\n",
    "            embeddings.grad.zero_()\n",
    "        prediction_score.backward()\n",
    "        \n",
    "        if embeddings.grad is not None:\n",
    "            relevance = (embeddings * embeddings.grad).sum(dim=-1)\n",
    "            relevance = relevance.squeeze(0).cpu().detach().numpy()\n",
    "            \n",
    "            max_abs = np.abs(relevance).max()\n",
    "            if max_abs > self.epsilon:\n",
    "                relevance = relevance / max_abs\n",
    "        else:\n",
    "            relevance = np.zeros(input_ids.shape[1])\n",
    "        \n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0].cpu().numpy())\n",
    "        importance = []\n",
    "        for token, rel_score in zip(tokens, relevance):\n",
    "            cleaned = self.clean_token(token)\n",
    "            if cleaned:\n",
    "                importance.append((cleaned, float(rel_score)))\n",
    "        \n",
    "        importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        return importance, target_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer = LIMEExplainer(predict_sentiment, num_samples=1000)\n",
    "shap_explainer = SHAPExplainer(predict_sentiment, num_samples=500)\n",
    "lrp_explainer = LRPExplainer(model, tokenizer, device)\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, text in enumerate(test_samples):\n",
    "    print(f\"\\nSample {idx+1}: {text}\")\n",
    "    \n",
    "    probs = predict_sentiment(text)[0]\n",
    "    pred_class = np.argmax(probs)\n",
    "    pred_label = id2label[pred_class]\n",
    "    \n",
    "    print(f\"Prediction: {pred_label} ({probs[pred_class]:.3f})\")\n",
    "    \n",
    "    lime_features, _ = lime_explainer.explain(text)\n",
    "    shap_features, _ = shap_explainer.explain(text)\n",
    "    lrp_features, _ = lrp_explainer.explain(text)\n",
    "    \n",
    "    results.append({\n",
    "        'sample_id': idx + 1,\n",
    "        'text': text,\n",
    "        'prediction': pred_label,\n",
    "        'confidence': probs[pred_class],\n",
    "        'lime_features': lime_features[:5],\n",
    "        'shap_features': shap_features[:5],\n",
    "        'lrp_features': lrp_features[:5]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(sample_result):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    method_names = ['LIME', 'SHAP', 'LRP']\n",
    "    method_keys = ['lime_features', 'shap_features', 'lrp_features']\n",
    "\n",
    "    for idx, (method_key, method_name, ax) in enumerate(zip(method_keys, method_names, axes)):\n",
    "        features = sample_result[method_key]\n",
    "        features_sorted = sorted(features, key=lambda x: abs(x[1]), reverse=True)\n",
    "        words, scores = zip(*features_sorted)\n",
    "\n",
    "        words = list(reversed(words))\n",
    "        scores = list(reversed(scores))\n",
    "\n",
    "        if method_key == 'lrp_features':\n",
    "            colors = ['#3498db'] * len(scores)\n",
    "        else:\n",
    "            colors = ['#2ecc71' if s > 0 else '#e74c3c' for s in scores]\n",
    "\n",
    "        ax.barh(range(len(words)), scores, color=colors, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "        ax.set_yticks(range(len(words)))\n",
    "        ax.set_yticklabels(words, fontsize=12, fontweight='bold')\n",
    "        ax.set_title(method_name, fontsize=14, fontweight='bold', pad=10)\n",
    "\n",
    "        if method_key != 'lrp_features':\n",
    "            ax.axvline(x=0, color='black', linewidth=1.5, linestyle='--')\n",
    "\n",
    "        ax.grid(axis='x', alpha=0.3, linestyle=':')\n",
    "        ax.set_xlabel('Importance Score', fontsize=11)\n",
    "\n",
    "    text_preview = sample_result['text'][:80] + '...' if len(sample_result['text']) > 80 else sample_result['text']\n",
    "    title = f\"Sample {sample_result['sample_id']}: \\\"{text_preview}\\\"\\nPrediction: {sample_result['prediction']} (Confidence: {sample_result['confidence']:.1%})\"\n",
    "    plt.suptitle(title, fontsize=12, fontweight='bold', y=1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for idx in range(len(results)):\n",
    "    visualize_comparison(results[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.35, wspace=0.3)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "agreement_matrix = []\n",
    "for result in results:\n",
    "    lime_words = set([w.lower() for w, _ in result['lime_features']])\n",
    "    shap_words = set([w.lower() for w, _ in result['shap_features']])\n",
    "    lrp_words = set([w.lower() for w, _ in result['lrp_features']])\n",
    "\n",
    "    agreement_matrix.append([\n",
    "        len(lime_words & shap_words),\n",
    "        len(lime_words & lrp_words),\n",
    "        len(shap_words & lrp_words),\n",
    "        len(lime_words & shap_words & lrp_words)\n",
    "    ])\n",
    "\n",
    "agreement_matrix = np.array(agreement_matrix)\n",
    "im1 = ax1.imshow(agreement_matrix.T, cmap='YlGn', aspect='auto', vmin=0, vmax=5)\n",
    "ax1.set_yticks(range(4))\n",
    "ax1.set_yticklabels(['L-S', 'L-LRP', 'S-LRP', 'All 3'], fontsize=11, fontweight='bold')\n",
    "ax1.set_xticks(range(len(results)))\n",
    "ax1.set_xticklabels([f\"S{r['sample_id']}\" for r in results], fontsize=10)\n",
    "ax1.set_xlabel('Sample', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Feature Agreement Between Methods', fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(len(results)):\n",
    "        ax1.text(j, i, int(agreement_matrix[j, i]), ha=\"center\", va=\"center\", color=\"black\", fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.colorbar(im1, ax=ax1, label='Shared Features')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "confidences = [r['confidence'] for r in results]\n",
    "predictions = [r['prediction'] for r in results]\n",
    "colors = ['#2ecc71' if p == 'Positive' else '#e74c3c' if p == 'Negative' else '#f39c12' for p in predictions]\n",
    "\n",
    "ax2.bar(range(len(results)), confidences, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.set_xlabel('Sample', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Confidence', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Prediction Confidence', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(len(results)))\n",
    "ax2.set_xticklabels([f\"S{i+1}\" for i in range(len(results))])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "avg_agreements = agreement_matrix.mean(axis=0)\n",
    "pairs = ['L-S', 'L-LRP', 'S-LRP', 'All 3']\n",
    "\n",
    "ax3.bar(pairs, avg_agreements, color=['#3498db', '#9b59b6', '#e67e22', '#e74c3c'], alpha=0.7, edgecolor='black')\n",
    "ax3.set_ylabel('Avg Shared Features', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Average Agreement', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylim(0, 5)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(avg_agreements):\n",
    "    ax3.text(i, val + 0.1, f'{val:.1f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[2, :])\n",
    "all_features = {}\n",
    "for result in results:\n",
    "    for word, _ in (result['lime_features'][:3] + result['shap_features'][:3] + result['lrp_features'][:3]):\n",
    "        word = word.lower().strip('.,!?')\n",
    "        if word:\n",
    "            all_features[word] = all_features.get(word, 0) + 1\n",
    "\n",
    "top_features = sorted(all_features.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "words, counts = zip(*top_features)\n",
    "colors_freq = plt.cm.viridis(np.linspace(0.3, 0.9, len(words)))\n",
    "\n",
    "ax4.barh(range(len(words)), counts, color=colors_freq, alpha=0.8, edgecolor='black')\n",
    "ax4.set_yticks(range(len(words)))\n",
    "ax4.set_yticklabels(words, fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Most Influential Features', fontsize=14, fontweight='bold')\n",
    "ax4.invert_yaxis()\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, count in enumerate(counts):\n",
    "    ax4.text(count + 0.3, i, f'{int(count)}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Summary Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average confidence: {np.mean(confidences):.1%}\")\n",
    "print(f\"Average agreement (all 3): {avg_agreements[3]:.2f} features\")\n",
    "print(f\"Most influential word: '{top_features[0][0]}' ({top_features[0][1]} appearances)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
